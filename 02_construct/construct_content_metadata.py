import os
import json
import pandas as pd
from tqdm import tqdm
from openpyxl import load_workbook
from openpyxl.styles import Alignment

def extract_neighbors_by_elementid(df):
    """
    content (chunk_with_neighbors) ìƒì„± í•¨ìˆ˜  
    â†’ ì´ì „ì²­í¬, í˜„ì¬ì²­í¬, ë‹¤ìŒì²­í¬ ê°ê°ì— ë¼ë²¨ì„ ë¶™ì—¬ ê²°í•©
    """
    df["elementid"] = df["elementid"].astype(int)
    df_sorted = df.sort_values(by="elementid").reset_index(drop=True)
    # "ë‚´ìš©" ì—´ì€ ì´ë¯¸ì§€ì„¤ëª…ì´ ë°˜ì˜ëœ ìƒíƒœë¼ê³  ê°€ì •
    elementid_to_content = dict(zip(df_sorted["elementid"], df_sorted["ë‚´ìš©"]))
    content_list = []
    for eid in df_sorted["elementid"]:
        prev = elementid_to_content.get(eid - 1, "")
        curr = elementid_to_content.get(eid, "")
        next_ = elementid_to_content.get(eid + 1, "")
        parts = [
            "[[[[[[ì´ì „ì²­í¬]", prev,
            "[[[[[[í˜„ì¬ì²­í¬]", curr,
            "[[[[[[ë‹¤ìŒì²­í¬]", next_
        ]
        combined = "\n\n".join(parts)
        content_list.append(combined)
    return content_list

def extract_page_plus_chunk(df):
    """
    content (page_plus_chunk) ìƒì„± í•¨ìˆ˜  
    â†’ í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©ê³¼ í˜„ì¬ì²­í¬ì— ëŒ€í•´ ë¼ë²¨ì„ ë¶™ì—¬ ê²°í•©
    """
    df["í˜ì´ì§€ìˆ«ì"] = df["í˜ì´ì§€ìˆ«ì"].astype(str)
    page_to_all_text = df.groupby("í˜ì´ì§€ìˆ«ì")["ë‚´ìš©"].apply(lambda x: "\n\n".join(x)).to_dict()
    content_list = []
    for _, row in df.iterrows():
        page = row["í˜ì´ì§€ìˆ«ì"]
        chunk = row["ë‚´ìš©"]
        full_page = page_to_all_text.get(page, "")
        parts = [
            "[[[[[[í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©]", full_page,
            "[[[[[[í˜„ì¬ì²­í¬]", chunk
        ]
        combined = "\n\n".join(parts)
        content_list.append(combined)
    return content_list

def extract_page_only(df):
    """
    content (page_only) ìƒì„± í•¨ìˆ˜  
    â†’ í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©ì„ ë¼ë²¨ê³¼ í•¨ê»˜ í‘œì‹œ
    """
    df["í˜ì´ì§€ìˆ«ì"] = df["í˜ì´ì§€ìˆ«ì"].astype(str)
    page_to_all_text = df.groupby("í˜ì´ì§€ìˆ«ì")["ë‚´ìš©"].apply(lambda x: "\n\n".join(x)).to_dict()
    content_list = []
    for _, row in df.iterrows():
        page = row["í˜ì´ì§€ìˆ«ì"]
        full_page = page_to_all_text.get(page, "")
        combined = "[[[[[[í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©]\n\n" + full_page
        content_list.append(combined)
    return content_list

def get_neighbor_metadata(df):
    """
    metadata -1 ìƒì„± í•¨ìˆ˜ (ì²­í¬ ê¸°ë°˜)  
    â†’ ì´ì „ì²­í¬, í˜„ì¬ì²­í¬, ë‹¤ìŒì²­í¬ë¥¼ ë¼ë²¨ê³¼ í•¨ê»˜ ê²°í•©í•˜ê³ , 
        ê° í–‰ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ JSON ê°ì²´ë¡œ ìƒì„±  

    JSON ê°ì²´ í˜•ì‹:
    {
        "elementid": [int],         # í˜„ì¬ í–‰ì˜ elementid (ë¦¬ìŠ¤íŠ¸)
        "category": str,            # data-category ê°’
        "filename": str,            # íŒŒì¼ëª…
        "page": [int],              # í˜„ì¬ í–‰ì˜ í˜ì´ì§€ìˆ«ì (ë¦¬ìŠ¤íŠ¸)
        "text": str               # ë¼ë²¨ì´ í¬í•¨ëœ ê²°í•© í…ìŠ¤íŠ¸
    }
    """
    df["elementid"] = df["elementid"].astype(int)
    df["í˜ì´ì§€ìˆ«ì"] = df["í˜ì´ì§€ìˆ«ì"].astype(int)
    df_sorted = df.sort_values(by="elementid").reset_index(drop=True)
    elementid_to_content = dict(zip(df_sorted["elementid"], df_sorted["ë‚´ìš©"]))
    metadata = []
    for _, row in df_sorted.iterrows():
        eid = row["elementid"]
        prev = elementid_to_content.get(eid - 1, "")
        curr = elementid_to_content.get(eid, "")
        next_ = elementid_to_content.get(eid + 1, "")
        parts = [
            "[[[[[[ì´ì „ì²­í¬]", prev,
            "[[[[[[í˜„ì¬ì²­í¬]", curr,
            "[[[[[[ë‹¤ìŒì²­í¬]", next_
        ]
        combined_text = "\n\n".join(parts)
        meta_obj = {
            "elementid": [eid],
            "category": row["data-category"],
            "filename": row["íŒŒì¼ëª…"],
            "page": [row["í˜ì´ì§€ìˆ«ì"]],
            "text": combined_text
        }
        metadata.append(meta_obj)
    return metadata

def get_3page_metadata(df):
    """
    metadata -2 ìƒì„± í•¨ìˆ˜ (í˜ì´ì§€ ê¸°ë°˜)  
    â†’ ì´ì „í˜ì´ì§€, í˜„ì¬í˜ì´ì§€, ë‹¤ìŒí˜ì´ì§€ ì „ì²´ ë‚´ìš©ì„ ë¼ë²¨ê³¼ í•¨ê»˜ ê²°í•©í•˜ê³ ,
       í•´ë‹¹ í˜ì´ì§€ì— ì†í•œ ëª¨ë“  elementidì™€ í˜ì´ì§€ ìˆ«ìë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê¸°ë¡  
       
    JSON ê°ì²´ í˜•ì‹:
    {
        "elementid": [int, int, ...],  # í•´ë‹¹ í˜ì´ì§€(ì´ì „+í˜„ì¬+ë‹¤ìŒ)ì˜ ëª¨ë“  elementid
        "category": str,               # í˜„ì¬ í–‰ì˜ data-category
        "filename": str,               # íŒŒì¼ëª…
        "page": [int, int, ...],       # í•´ë‹¹ í˜ì´ì§€(ì´ì „+í˜„ì¬+ë‹¤ìŒ)ì˜ í˜ì´ì§€ìˆ«ì ë¦¬ìŠ¤íŠ¸
        "text": str                  # ë¼ë²¨ í¬í•¨ ê²°í•© í…ìŠ¤íŠ¸
    }
    """
    df["í˜ì´ì§€ìˆ«ì"] = df["í˜ì´ì§€ìˆ«ì"].astype(int)
    # í˜ì´ì§€ë³„ ì „ì²´ í…ìŠ¤íŠ¸
    page_to_text = df.groupby("í˜ì´ì§€ìˆ«ì")["ë‚´ìš©"].apply(lambda x: "\n\n".join(x)).to_dict()
    metadata = []
    for _, row in df.iterrows():
        current_page = int(row["í˜ì´ì§€ìˆ«ì"])
        prev_text = page_to_text.get(current_page - 1, "")
        current_text = page_to_text.get(current_page, "")
        next_text = page_to_text.get(current_page + 1, "")
        parts = [
            "[[[[[[ì´ì „í˜ì´ì§€]", prev_text,
            "[[[[[[í˜„ì¬í˜ì´ì§€]", current_text,
            "[[[[[[ë‹¤ìŒí˜ì´ì§€]", next_text
        ]
        combined_text = "\n\n".join(parts)
        # í•´ë‹¹ í˜ì´ì§€(ì´ì „, í˜„ì¬, ë‹¤ìŒ)ë³„ elementidì™€ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        prev_ids = df[df["í˜ì´ì§€ìˆ«ì"] == (current_page - 1)]["elementid"].tolist()
        curr_ids = df[df["í˜ì´ì§€ìˆ«ì"] == current_page]["elementid"].tolist()
        next_ids = df[df["í˜ì´ì§€ìˆ«ì"] == (current_page + 1)]["elementid"].tolist()
        all_ids = prev_ids + curr_ids + next_ids
        all_pages = ([current_page - 1] * len(prev_ids)) + ([current_page] * len(curr_ids)) + ([current_page + 1] * len(next_ids))
        meta_obj = {
            "elementid": all_ids,
            "category": row["data-category"],
            "filename": row["íŒŒì¼ëª…"],
            "page": all_pages,
            "text": combined_text
        }
        metadata.append(meta_obj)
    return metadata

def get_cross_page_metadata(df):
    """
    metadata -3 ìƒì„± í•¨ìˆ˜ (í˜ì´ì§€ ê¸°ë°˜)  
    â†’ í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©, ì´ì „í˜ì´ì§€ ë§ˆì§€ë§‰ ì²­í¬, ë‹¤ìŒí˜ì´ì§€ ì²«ë²ˆì§¸ ì²­í¬ë¥¼ ë¼ë²¨ê³¼ í•¨ê»˜ ê²°í•©í•˜ê³ ,
       í˜„ì¬ í˜ì´ì§€ ê·¸ë£¹ì˜ ëª¨ë“  elementid, ê·¸ë¦¬ê³  ì´ì „/ë‹¤ìŒ í˜ì´ì§€ì˜ í•´ë‹¹ ì²­í¬ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê¸°ë¡
       
    JSON ê°ì²´ í˜•ì‹:
    {
        "elementid": [int, ...],  # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  elementid + (ì´ì „í˜ì´ì§€ ë§ˆì§€ë§‰, ë‹¤ìŒí˜ì´ì§€ ì²«ë²ˆì§¸)
        "category": str,           # í˜„ì¬ í–‰ì˜ data-category
        "filename": str,           # íŒŒì¼ëª…
        "page": [int, ...],        # í˜„ì¬ í˜ì´ì§€ì˜ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ + ì´ì „, ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ (ê°ê° 1ê°œì”©)
        "text": str             # ë¼ë²¨ í¬í•¨ ê²°í•© í…ìŠ¤íŠ¸
    }
    """
    df["elementid"] = df["elementid"].astype(int)
    df["í˜ì´ì§€ìˆ«ì"] = df["í˜ì´ì§€ìˆ«ì"].astype(int)
    page_groups = df.groupby("í˜ì´ì§€ìˆ«ì")
    page_dict = {}
    for page, group in page_groups:
        group_sorted = group.sort_values("elementid")
        full_text = "\n\n".join(group_sorted["ë‚´ìš©"].tolist())
        first_chunk = group_sorted.iloc[0]["ë‚´ìš©"]
        last_chunk = group_sorted.iloc[-1]["ë‚´ìš©"]
        elem_ids = group_sorted["elementid"].tolist()
        page_dict[page] = {"full": full_text, "first": first_chunk, "last": last_chunk, "ids": elem_ids}
    metadata = []
    for _, row in df.iterrows():
        current_page = int(row["í˜ì´ì§€ìˆ«ì"])
        current_full = page_dict.get(current_page, {}).get("full", "")
        prev_last = page_dict.get(current_page - 1, {}).get("last", "")
        next_first = page_dict.get(current_page + 1, {}).get("first", "")
        parts = [
            "[[[[[[í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©]", current_full,
            "[[[[[[ì´ì „í˜ì´ì§€ ë§ˆì§€ë§‰ ì²­í¬]", prev_last,
            "[[[[[[ë‹¤ìŒí˜ì´ì§€ ì²«ë²ˆì§¸ ì²­í¬]", next_first
        ]
        combined_text = "\n\n".join(parts)
        current_ids = page_dict.get(current_page, {}).get("ids", [])
        prev_ids = df[df["í˜ì´ì§€ìˆ«ì"] == (current_page - 1)]["elementid"].tolist()
        next_ids = df[df["í˜ì´ì§€ìˆ«ì"] == (current_page + 1)]["elementid"].tolist()
        prev_last_id = [prev_ids[-1]] if prev_ids else []
        next_first_id = [next_ids[0]] if next_ids else []
        all_ids = current_ids + prev_last_id + next_first_id
        current_pages = [current_page] * len(current_ids)
        prev_page_list = [current_page - 1] if prev_ids else []
        next_page_list = [current_page + 1] if next_ids else []
        all_pages = current_pages + prev_page_list + next_page_list
        meta_obj = {
            "elementid": all_ids,
            "category": row["data-category"],
            "filename": row["íŒŒì¼ëª…"],
            "page": all_pages,
            "text": combined_text
        }
        metadata.append(meta_obj)
    return metadata

def save_excel(content_list, metadata_list, output_path):
    # metadata_listì˜ ê° JSON ê°ì²´ë¥¼ ì¤„ë°”ê¿ˆì´ í¬í•¨ëœ ë¬¸ìì—´ë¡œ ë³€í™˜ (indent=4)
    metadata_json = [json.dumps(item, ensure_ascii=False, indent=4) for item in metadata_list]
    out_df = pd.DataFrame({
        "content": content_list,
        "metadata": metadata_json
    })
    out_df.to_excel(output_path, index=False)
    
    # openpyxlì„ ì‚¬ìš©í•˜ì—¬ ì—‘ì…€ ì„œì‹ ì ìš©
    wb = load_workbook(output_path)
    ws = wb.active
    ws.column_dimensions['A'].width = 80
    ws.column_dimensions['B'].width = 80
    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=2):
        for cell in row:
            cell.alignment = Alignment(wrap_text=True, vertical='top')
    wb.save(output_path)

def construct_embedding_contents(base_folder):
    base_name = os.path.basename(os.path.normpath(base_folder))
    excel_path = os.path.join(base_folder, f"{base_name}.xlsx")
    if not os.path.exists(excel_path):
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {excel_path}")
        return

    df = pd.read_excel(excel_path)
    # "ì´ë¯¸ì§€ì„¤ëª…" ì—´ì´ ìˆë‹¤ë©´, í•´ë‹¹ í–‰ì˜ "ë‚´ìš©"ì— ì¶”ê°€í•˜ì—¬ í˜„ì¬ ì²­í¬ì˜ ë‚´ìš©ì— í¬í•¨ì‹œí‚´
    if "ì´ë¯¸ì§€ì„¤ëª…" in df.columns:
        df["ë‚´ìš©"] = df.apply(
            lambda row: row["ë‚´ìš©"] + ( "\n\nì´ë¯¸ì§€ì„¤ëª…: " + str(row["ì´ë¯¸ì§€ì„¤ëª…"]) 
                                        if pd.notna(row["ì´ë¯¸ì§€ì„¤ëª…"]) and str(row["ì´ë¯¸ì§€ì„¤ëª…"]).strip() != "" 
                                        else "" ),
            axis=1
        )
    
    os.makedirs(os.path.join(base_folder, "before"), exist_ok=True)
    # content ìƒì„±
    content_map = {
        "chunk_only": df["ë‚´ìš©"].tolist(),  # ì›ë³¸ ì²­í¬ (ì´ë¯¸ì§€ì„¤ëª… í¬í•¨)
        "chunk_with_neighbors": extract_neighbors_by_elementid(df),
        "page_plus_chunk": extract_page_plus_chunk(df),
        "page_only": extract_page_only(df)
    }
    content_type_mapping = {
        "chunk_only": "1",
        "chunk_with_neighbors": "2",
        "page_plus_chunk": "3",
        "page_only": "4"
    }
    metadata_funcs = {
        "1": get_neighbor_metadata,
        "2": get_3page_metadata,
        "3": get_cross_page_metadata
    }
    # ê° content typeë³„ë¡œ ë©”íƒ€ë°ì´í„° ìƒì„± (chunk_only, chunk_with_neighbors, page_plus_chunk: -1, -2, -3 / page_only: -2, -3)
    for content_name, content_list in content_map.items():
        if content_name == "page_only":
            valid_meta_ids = ["2", "3"]
        else:
            valid_meta_ids = ["1", "2", "3"]
        for meta_id in valid_meta_ids:
            metadata_list = metadata_funcs[meta_id](df)
            filename = f"{content_type_mapping[content_name]}-{meta_id}_{content_name}.xlsx"
            save_path = os.path.join(base_folder, "before")
            save_file_path = os.path.join(save_path, filename)
            save_excel(content_list, metadata_list, save_file_path)
    print("â•‘ ğŸ“ ì´ 11ê°œì˜ content|metadata ì—‘ì…€ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return save_path

if __name__ == "__main__":
    base_folder = "data/250331-13-24_ëª¨ë‹ˆí„°1~3p"
    construct_embedding_contents(base_folder)
