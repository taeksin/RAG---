import os
import numpy as np
import pandas as pd
import faiss
import json
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv
from openai import OpenAI  # Upstage API ì‚¬ìš©

# Upstage APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
def get_upstage_embedding(texts, client, model):
    """
    Upstage APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ìƒì„± (batch_size=100)
    """
    embeddings = []
    batch_size = 100  # Upstage API ìµœëŒ€ ìš”ì²­ ê°œìˆ˜
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        try:
            response = client.embeddings.create(
                model=model,
                input=batch_texts
            )
            batch_embeddings = [item.embedding for item in response.data]
            embeddings.extend(batch_embeddings)
        except Exception as e:
            print(f"ğŸš¨ ì„ë² ë”© ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
    return embeddings

# UpstageEmbeddings í´ë˜ìŠ¤ (Embeddings ê°ì²´ êµ¬í˜„)
from langchain.embeddings.base import Embeddings

class UpstageEmbeddings(Embeddings):
    def __init__(self, client, model):
        self.client = client
        self.model = model

    def embed_documents(self, texts):
        return get_upstage_embedding(texts, self.client, self.model)

    def embed_query(self, text):
        return self.embed_documents([text])[0]

def upstageEmbedding(folder_path):
    """
    folder_path ë‚´ë¶€ì— ìˆëŠ” ëª¨ë“  Excel íŒŒì¼(.xlsx)ì„ ê°œë³„ë¡œ ì²˜ë¦¬í•˜ì—¬
    Upstage APIë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ê° Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ì‚¬ìš©í•˜ë©°, íŒŒì¼ë³„ë¡œ ë³„ë„ì˜ ë²¡í„°ìŠ¤í† ì–´ê°€ ìƒì„±ë©ë‹ˆë‹¤.
    """
    load_dotenv()

    # Upstage API í‚¤ ì„¤ì •
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        print("UPSTAGE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # Upstage API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.upstage.ai/v1/solar"
    )

    # folder_path ë‚´ì˜ ëª¨ë“  Excel íŒŒì¼ ì°¾ê¸°
    excel_files = []
    for f in os.listdir(folder_path):
        if f.lower().endswith('.xlsx'):
            file_path = os.path.join(folder_path, f)
            try:
                xl = pd.ExcelFile(file_path, engine='openpyxl')
                sheets = xl.sheet_names
                excel_files.append((file_path, sheets))
            except Exception as e:
                print(f"Excel íŒŒì¼ {f} ì½ê¸° ì‹¤íŒ¨: {e}")

    if not excel_files:
        print("ì²˜ë¦¬í•  Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í´ë” ë‚´ ê° Excel íŒŒì¼ë³„ë¡œ ê°œë³„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    for file, sheets in excel_files:
        file_documents = []
        for sheet in sheets:
            try:
                df = pd.read_excel(file, engine='openpyxl', sheet_name=sheet)
            except Exception as e:
                print(f"ì‹œíŠ¸ {sheet} ì½ê¸° ì‹¤íŒ¨: {e}")
                continue

            if "content" not in df.columns or "metadata" not in df.columns:
                print(f"íŒŒì¼ {file}ì˜ ì‹œíŠ¸ {sheet}ì— 'content' ë˜ëŠ” 'metadata' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue

            df = df.dropna(subset=["content", "metadata"])
            for _, row in df.iterrows():
                content = row["content"]
                for pattern in ["[[[[[[ì´ì „ì²­í¬]", "[[[[[[í˜„ì¬ì²­í¬]", "[[[[[[ë‹¤ìŒì²­í¬]",
                                "[[[[[[í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©]", "[[[[[[ì´ì „í˜ì´ì§€ ë§ˆì§€ë§‰ ì²­í¬]", "[[[[[[ë‹¤ìŒí˜ì´ì§€ ì²«ë²ˆì§¸ ì²­í¬]"]:
                    content = content.replace(pattern, "")
                try:
                    metadata = json.loads(row["metadata"])
                except Exception as e:
                    print(f"ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ (íŒŒì¼ {file}, ì‹œíŠ¸ {sheet}): {e}")
                    continue
                for pattern in ["[[[[[[ì´ì „ì²­í¬]", "[[[[[[í˜„ì¬ì²­í¬]", "[[[[[[ë‹¤ìŒì²­í¬]",
                                "[[[[[[í˜„ì¬í˜ì´ì§€ ì „ì²´ë‚´ìš©]", "[[[[[[ì´ì „í˜ì´ì§€ ë§ˆì§€ë§‰ ì²­í¬]", "[[[[[[ë‹¤ìŒí˜ì´ì§€ ì²«ë²ˆì§¸ ì²­í¬]"]:
                    metadata["text"] = metadata["text"].replace(pattern, "")
                file_documents.append(Document(page_content=content, metadata=metadata))
        
        if not file_documents:
            print(f"íŒŒì¼ {file}ì—ì„œ ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        file_text_contents = [doc.page_content for doc in file_documents]
        file_embeddings = get_upstage_embedding(file_text_contents, client, "embedding-passage")
        if len(file_embeddings) != len(file_documents):
            print("ğŸš¨ ì„ë² ë”© ê°œìˆ˜ê°€ ë¬¸ì„œ ê°œìˆ˜ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue

        dimension = len(file_embeddings[0])
        file_index = faiss.IndexFlatL2(dimension)
        # pylint: disable=no-value-for-parameter
        file_index.add(np.array(file_embeddings, dtype=np.float32))

        file_index_to_docstore_id = {i: str(i) for i in range(len(file_documents))}
        file_docstore = {str(i): doc for i, doc in enumerate(file_documents)}

        upstage_embedding_obj = UpstageEmbeddings(client, "embedding-passage")
        file_vectorstore = FAISS(
            embedding_function=upstage_embedding_obj,
            index=file_index,
            docstore=file_docstore,
            index_to_docstore_id=file_index_to_docstore_id
        )

        # ì—‘ì…€ íŒŒì¼ëª…(í™•ì¥ì ì œê±°) ì‚¬ìš©í•˜ì—¬ ì €ì¥ í´ë” ì§€ì •
        excel_filename = os.path.splitext(os.path.basename(file))[0]
        save_path = f"vdb/upstage_faiss/{excel_filename}_embedding-passage/"
        file_vectorstore.save_local(save_path)
        print(f"â•‘   -> {excel_filename} íŒŒì¼ì˜ ì„ë² ë”©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # print(f"âœ… FAISS ë²¡í„° ê°œìˆ˜: {file_vectorstore.index.ntotal}")
        # print(f"âœ… ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {len(file_vectorstore.docstore)}")

if __name__ == "__main__":
    folder_path = r"C:\Users\yoyo2\fas\RAG_Pre_processing\data\250331-16-57_ëª¨ë‹ˆí„°1p"
    upstageEmbedding(folder_path)
